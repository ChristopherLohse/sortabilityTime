{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching list of available datasets from https://causalchamber.s3.eu-central-1.amazonaws.com/downloadables/directory.yaml ... done.\n",
      "If you use our datasets or simulators for your work please consider citing:\n",
      "\n",
      "ï»¿@article{gamella2025chamber,\n",
      "  author={Gamella, Juan L. and Peters, Jonas and B{\"u}hlmann, Peter},\n",
      "  title={Causal chambers as a real-world physical testbed for {AI} methodology},\n",
      "  journal={Nature Machine Intelligence},\n",
      "  doi={10.1038/s42256-024-00964-x},\n",
      "  year={2025},\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sortabilitytime.sortnregress_time import (\n",
    "    var_sort_regress,\n",
    "    r2_sort_regress_ts,\n",
    "    r2_sort_regress,\n",
    "    random_sort_regress_ts,\n",
    "    random_sort_regress,\n",
    "    var_sort_regress_reverse,\n",
    "    var_sort_regress,\n",
    "    var_sort_regress_ts,\n",
    "    var_sort_regress_ts_reverse,\n",
    "    ts_graph_to_summary_graph,\n",
    ")\n",
    "from sortabilitytime.dynotears import Dynotears\n",
    "from sortabilitytime.sortability_ts import var_sortability, r2_sortability\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests.parcorr import ParCorr\n",
    "import tigramite.data_processing as pp\n",
    "from sklearn.metrics import f1_score\n",
    "from causalchamber.datasets import Dataset\n",
    "import tigramite.data_processing as pp\n",
    "from causalchamber.ground_truth import graph\n",
    "from tigramite.independence_tests.parcorr import ParCorr\n",
    "from causalchamber.ground_truth import graph\n",
    "# ignore warnings\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr(\n",
    "    significance=\"analytic\",\n",
    "    #                   mask_type='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_max = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided dataset information\n",
    "dataset_info = [\n",
    "    {\"name\": \"lt_camera_walks_v1\", \"chamber\": \"Light tunnel\", \"config\": \"camera\"},\n",
    "    {\"name\": \"lt_color_regression_v1\", \"chamber\": \"Light tunnel\", \"config\": \"camera\"},\n",
    "    {\n",
    "        \"name\": \"lt_interventions_standard_v1\",\n",
    "        \"chamber\": \"Light tunnel\",\n",
    "        \"config\": \"standard\",\n",
    "    },\n",
    "    {\"name\": \"lt_walks_v1\", \"chamber\": \"Light tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"wt_walks_v1\", \"chamber\": \"Wind tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"lt_malus_v1\", \"chamber\": \"Light tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"wt_bernoulli_v1\", \"chamber\": \"Wind tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"wt_changepoints_v1\", \"chamber\": \"Wind tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"wt_intake_impulse_v1\", \"chamber\": \"Wind tunnel\", \"config\": \"standard\"},\n",
    "    {\n",
    "        \"name\": \"wt_pressure_control_v1\",\n",
    "        \"chamber\": \"Wind tunnel\",\n",
    "        \"config\": \"pressure-control\",\n",
    "    },\n",
    "    {\"name\": \"lt_test_v1\", \"chamber\": \"Light tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"wt_test_v1\", \"chamber\": \"Wind tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"lt_camera_test_v1\", \"chamber\": \"Light tunnel\", \"config\": \"camera\"},\n",
    "    {\"name\": \"wt_validate_v1\", \"chamber\": \"Wind tunnel\", \"config\": \"standard\"},\n",
    "    {\n",
    "        \"name\": \"wt_pc_validate_v1\",\n",
    "        \"chamber\": \"Wind tunnel\",\n",
    "        \"config\": \"pressure-control\",\n",
    "    },\n",
    "    {\"name\": \"lt_validate_v1\", \"chamber\": \"Light tunnel\", \"config\": \"standard\"},\n",
    "    {\"name\": \"lt_camera_validate_v1\", \"chamber\": \"Light tunnel\", \"config\": \"standard\"},\n",
    "]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "f1_scores = {\n",
    "    \"f1_var_sortnregress\": [],\n",
    "    \"f1_r2_sortnregress\": [],\n",
    "    \"f1_random\": [],\n",
    "}\n",
    "\n",
    "for dataset_info_entry in dataset_info:\n",
    "    dataset_name = dataset_info_entry[\"name\"]\n",
    "    chamber = dataset_info_entry[\"chamber\"]\n",
    "    config = dataset_info_entry[\"config\"]\n",
    "    if chamber.lower() == \"wind tunnel\":\n",
    "        short_name = \"wt\"\n",
    "    elif chamber.lower() == \"light tunnel\":\n",
    "        short_name = \"lt\"\n",
    "    dataset = Dataset(name=dataset_name, root=\"../Data/Causalchamber\", download=True)\n",
    "    ground_truth = graph(chamber=short_name, configuration=config)\n",
    "\n",
    "    for experiment in dataset.available_experiments():\n",
    "        ground_truth = graph(chamber=short_name, configuration=config)\n",
    "\n",
    "        print(\n",
    "            f\"running {experiment} on {dataset_name} with config {config} and chamber {short_name}\"\n",
    "        )\n",
    "        df = dataset.get_experiment(name=experiment).as_pandas_dataframe()\n",
    "\n",
    "        # remove nans and infs from df\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.dropna()\n",
    "\n",
    "        try:\n",
    "            df = df[ground_truth.columns]\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(\n",
    "            f\"error in {experiment} on {dataset_name} with config {config} and chamber {short_name}\"\n",
    "            )\n",
    "            ground_truth = ground_truth.drop(columns=[\"im\"])\n",
    "            ground_truth = ground_truth.drop(index=[\"im\"])\n",
    "            df = df[ground_truth.columns]\n",
    "\n",
    "        var = var_sortability(df.to_numpy(), ground_truth.to_numpy())\n",
    "        r2 = r2_sortability(df.to_numpy(), ground_truth.to_numpy())\n",
    "\n",
    "        # remove infs and nans in gruond_truth\n",
    "        ground_truth = ground_truth.replace([np.inf, -np.inf], np.nan)\n",
    "        ground_truth = ground_truth.dropna()\n",
    "\n",
    "        # also in data\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        df = df.dropna()\n",
    "\n",
    "        data = df.to_numpy()\n",
    "\n",
    "        dataframe = pp.DataFrame(\n",
    "            data.copy(), mask=None, datatime={0: np.arange(len(data))}\n",
    "        )\n",
    "        # dynotears = Dynotears(dataframe=dataframe)\n",
    "        # w_est, a_est, string_graph, a_est_dyno = dynotears.run_dynotears(\n",
    "        #     tau_max=3, max_iter=100, w_threshold=0.1, lambda_a=0.1, lambda_w=0.1\n",
    "        # )\n",
    "\n",
    "        # a_est_dyno = ts_graph_to_summary_graph(a_est_dyno)\n",
    "\n",
    "        # f1_dynotears = f1_score(ground_truth.to_numpy().flatten(), a_est_dyno.flatten())\n",
    "        try:\n",
    "            data = df.to_numpy()\n",
    "            dataframe = pp.DataFrame(data)\n",
    "            pcmci = PCMCI(dataframe=dataframe, cond_ind_test=parcorr, verbosity=0)\n",
    "            results_pcmci = pcmci.run_pcmciplus(tau_max=3, pc_alpha=0.01)\n",
    "            results_pcmci[\"p_matrix\"] = np.where(\n",
    "                results_pcmci[\"p_matrix\"] < 0.01, results_pcmci[\"p_matrix\"], 0\n",
    "            )\n",
    "            a_pcmci = results_pcmci[\"p_matrix\"]\n",
    "            a_pcmci[a_pcmci != 0] = 1\n",
    "\n",
    "            a_pcmci = ts_graph_to_summary_graph(a_pcmci)\n",
    "\n",
    "            G_true = ground_truth.to_numpy()\n",
    "\n",
    "            a_est_var_sortnregress = var_sort_regress_ts(data, tau_max=tau_max)\n",
    "\n",
    "            a_est_var_sortnregress_reverse = var_sort_regress_ts_reverse(data, tau_max=tau_max)\n",
    "            a_est_r2_sortnregress = r2_sort_regress_ts(data, tau_max=tau_max)\n",
    "            a_est_random = random_sort_regress_ts(data, tau_max=tau_max)\n",
    "            a_est_var_sortnregress[:, :, 0] = var_sort_regress(data)\n",
    "            a_est_r2_sortnregress[:, :, 0] = r2_sort_regress(data)\n",
    "            a_est_var_sortnregress_reverse[:, :, 0] = var_sort_regress_reverse(data)\n",
    "            a_est_random[:, :, 0] = random_sort_regress(data)\n",
    "            a_est_var_sortnregress = ts_graph_to_summary_graph(a_est_var_sortnregress)\n",
    "\n",
    "            a_est_var_sortnregress_reverse = ts_graph_to_summary_graph(\n",
    "                a_est_var_sortnregress_reverse\n",
    "            )\n",
    "\n",
    "            a_est_r2_sortnregress = ts_graph_to_summary_graph(a_est_r2_sortnregress)\n",
    "\n",
    "            a_est_random = ts_graph_to_summary_graph(a_est_random)\n",
    "\n",
    "            # replace all values above !=0 with 1\n",
    "            a_est_var_sortnregress[a_est_var_sortnregress != 0] = 1\n",
    "            a_est_r2_sortnregress[a_est_r2_sortnregress != 0] = 1\n",
    "            a_est_random[a_est_random != 0] = 1\n",
    "            f1_var_sortnregress = f1_score(\n",
    "                G_true.flatten(), a_est_var_sortnregress.flatten()\n",
    "            )\n",
    "\n",
    "            f1_var_sortnregress_reverse = f1_score(\n",
    "                G_true.flatten(), a_est_var_sortnregress_reverse.flatten()\n",
    "            )\n",
    "            f1_r2_sortnregress = f1_score(G_true.flatten(), a_est_r2_sortnregress.flatten())\n",
    "            f1_random = f1_score(G_true.flatten(), a_est_random.flatten())\n",
    "            f1_pcmci = f1_score(G_true.flatten(), a_pcmci.flatten())\n",
    "\n",
    "            result = {\n",
    "                \"var_sortability\": var,\n",
    "                \"r2_sortability\": r2,\n",
    "                # \"f1_dynotears\": f1_dynotears,\n",
    "                \"f1_pcmci\": f1_pcmci,\n",
    "                \"f1_var_sortnregress\": f1_var_sortnregress,\n",
    "                \"f1_var_sortnregress_reverse\": f1_var_sortnregress_reverse,\n",
    "                \"f1_r2_sortnregress\": f1_r2_sortnregress,\n",
    "                \"f1_random\": f1_random,\n",
    "            }\n",
    "            results_dict[f\"{dataset_name}+{experiment}\"] = result\n",
    "\n",
    "        except: \n",
    "            result = {\n",
    "                \"var_sortability\": var,\n",
    "                \"r2_sortability\": r2,\n",
    "                # \"f1_dynotears\": f1_dynotears,\n",
    "                \"f1_pcmci\": np.nan,\n",
    "                \"f1_var_sortnregress\": np.nan,\n",
    "                \"f1_var_sortnregress_reverse\": np.nan,\n",
    "                \"f1_r2_sortnregress\": np.nan,\n",
    "                \"f1_random\": np.nan,\n",
    "            }\n",
    "            results_dict[f\"{dataset_name}+{experiment}\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_dict)\n",
    "\n",
    "df = df.T\n",
    "for index in df.index:\n",
    "    if \"+\" not in index:\n",
    "        df = df.drop(index)\n",
    "df = df.round(2)\n",
    "df[\"Experiment\"] = df.index.str.split(\"+\").str[1]\n",
    "df[\"Dataset\"] = df.index.str.split(\"+\").str[0]\n",
    "\n",
    "# remove index and set dataset as first and experiment as second column\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# df = df[[\"Dataset\", \"Experiment\", \"var_sortability\", \"r2_sortability\"]]\n",
    "\n",
    "# df.to_latex(\"results_causalchamber.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_columns = [\n",
    "    \"var_sortability\",\n",
    "    \"r2_sortability\",\n",
    "    \"f1_pcmci\",\n",
    "    \"f1_var_sortnregress\",\n",
    "    \"f1_var_sortnregress_reverse\",\n",
    "    \"f1_r2_sortnregress\",\n",
    "    \"f1_random\",\n",
    "]\n",
    "df_grouped = df.groupby(\"Dataset\").agg({col: [\"mean\", \"std\"] for col in agg_columns})\n",
    "df_grouped = df_grouped.round(2)\n",
    "df_grouped = df_grouped.fillna(0)\n",
    "\n",
    "df_grouped.columns = [\"_\".join(col) for col in df_grouped.columns]\n",
    "\n",
    "for col in agg_columns:\n",
    "    mean_col = f\"{col}_mean\"\n",
    "    std_col = f\"{col}_std\"\n",
    "    df_grouped[col] = (\n",
    "        df_grouped[mean_col].astype(str) + \" $\\pm$ \" + df_grouped[std_col].astype(str)\n",
    "    )\n",
    "\n",
    "df_grouped = df_grouped.drop(\n",
    "    columns=[f\"{col}_mean\" for col in agg_columns]\n",
    "    + [f\"{col}_std\" for col in agg_columns]\n",
    ")\n",
    "df_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sortabilitytime-wasiI92U-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
